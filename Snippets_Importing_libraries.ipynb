{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sujitha24-dotcom/Personal-Bucket-List-Project/blob/main/Snippets_Importing_libraries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDn_lVxg3Z2G"
      },
      "source": [
        "# Importing a library that is not in Colaboratory\n",
        "\n",
        "To import a library that's not in Colaboratory by default, you can use `!pip install` or `!apt-get install`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YcNJokcz2rEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pgmpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77UV9scR2qeL",
        "outputId": "abb2a945-4673-4746-b612-e81a235852ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pgmpy in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pgmpy) (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pgmpy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pgmpy) (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from pgmpy) (2.6.0+cu124)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from pgmpy) (0.14.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pgmpy) (4.67.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.4.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from pgmpy) (3.4.0)\n",
            "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.11/dist-packages (from pgmpy) (1.9.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pgmpy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pgmpy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pgmpy) (2025.2)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl->pgmpy) (0.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (4.13.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->pgmpy) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->pgmpy) (1.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->pgmpy) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pgmpy) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels->pgmpy) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pgmpy) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->pgmpy) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAB 05"
      ],
      "metadata": {
        "id": "qsTq4Ku15HCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pgmpy.models import DiscreteBayesianNetwork\n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "# Define the structure of the Bayesian Network\n",
        "model = DiscreteBayesianNetwork([('GeneA', 'GeneC'), ('GeneB', 'GeneC'), ('GeneC', 'Phenotype')])\n",
        "\n",
        "# Example dataset (simulated genetic interactions)\n",
        "data = pd.DataFrame(\n",
        "    np.random.randint(0, 2, size=(1000, 4)), columns=['GeneA', 'GeneB', 'GeneC', 'Phenotype']\n",
        ")\n",
        "\n",
        "# Learning the CPDs using Maximum Likelihood Estimation\n",
        "model.fit(data, estimator=MaximumLikelihoodEstimator)\n",
        "\n",
        "# Performing inference\n",
        "inference = VariableElimination(model)\n",
        "\n",
        "# Query: Probability of Phenotype given GeneA is active (1)\n",
        "query_result = inference.query(variables=['Phenotype'], evidence={'GeneA': 1})\n",
        "print(query_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAEYapRD3YK-",
        "outputId": "c7adb8b2-f6c0-4c2f-e7e0-8254c8be2a0e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+------------------+\n",
            "| Phenotype    |   phi(Phenotype) |\n",
            "+==============+==================+\n",
            "| Phenotype(0) |           0.5173 |\n",
            "+--------------+------------------+\n",
            "| Phenotype(1) |           0.4827 |\n",
            "+--------------+------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAB 06"
      ],
      "metadata": {
        "id": "Fzpqb-hU5aZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pgmpy.models import DiscreteBayesianNetwork\n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "# Define Bayesian Network structure\n",
        "model = DiscreteBayesianNetwork([\n",
        "    ('NodeA', 'NodeC'),\n",
        "    ('NodeB', 'NodeC'),\n",
        "    ('NodeC', 'Output')\n",
        "])\n",
        "\n",
        "# Generate synthetic dataset with new probabilities\n",
        "np.random.seed(42)\n",
        "data = pd.DataFrame({\n",
        "    'NodeA': np.random.choice([0, 1], size=1000, p=[0.4, 0.6]),\n",
        "    'NodeB': np.random.choice([0, 1], size=1000, p=[0.7, 0.3]),\n",
        "    'NodeC': np.random.choice([0, 1], size=1000, p=[0.5, 0.5]),\n",
        "    'Output': np.random.choice([0, 1], size=1000, p=[0.6, 0.4])\n",
        "})\n",
        "\n",
        "# Learn CPDs using Maximum Likelihood Estimation\n",
        "model.fit(data, estimator=MaximumLikelihoodEstimator)\n",
        "\n",
        "# Function to perform inference\n",
        "def perform_inference(evidence):\n",
        "    inference = VariableElimination(model)\n",
        "    result = inference.query(variables=['Output'], evidence=evidence)\n",
        "    return result\n",
        "\n",
        "# Running inference sequentially (multiprocessing removed due to pgmpy limitations)\n",
        "def run_inference():\n",
        "    evidences = [{'NodeA': 1}, {'NodeB': 0}, {'NodeC': 1}]\n",
        "\n",
        "    results = [perform_inference(evidence) for evidence in evidences]\n",
        "\n",
        "    # Print results in table format\n",
        "    for idx, res in enumerate(results, 1):\n",
        "        print(f\"=== Inference Result {idx} ===\")\n",
        "        print(res)\n",
        "        print(\"========================\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_inference()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYot-IPT4esW",
        "outputId": "8e5121cc-aaf4-436c-a5df-78c612cb101b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Inference Result 1 ===\n",
            "+-----------+---------------+\n",
            "| Output    |   phi(Output) |\n",
            "+===========+===============+\n",
            "| Output(0) |        0.6089 |\n",
            "+-----------+---------------+\n",
            "| Output(1) |        0.3911 |\n",
            "+-----------+---------------+\n",
            "========================\n",
            "\n",
            "=== Inference Result 2 ===\n",
            "+-----------+---------------+\n",
            "| Output    |   phi(Output) |\n",
            "+===========+===============+\n",
            "| Output(0) |        0.6090 |\n",
            "+-----------+---------------+\n",
            "| Output(1) |        0.3910 |\n",
            "+-----------+---------------+\n",
            "========================\n",
            "\n",
            "=== Inference Result 3 ===\n",
            "+-----------+---------------+\n",
            "| Output    |   phi(Output) |\n",
            "+===========+===============+\n",
            "| Output(0) |        0.6076 |\n",
            "+-----------+---------------+\n",
            "| Output(1) |        0.3924 |\n",
            "+-----------+---------------+\n",
            "========================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAB 07"
      ],
      "metadata": {
        "id": "QqzTE6NV5quS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_WSkZqGz4vO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import multiprocessing\n",
        "\n",
        "# Define a function to generate a categorical probability output\n",
        "def generate_categorical_data(seed=None):\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)  # Ensure each process has a different seed\n",
        "\n",
        "    states = [\"High\", \"Low\"]\n",
        "    action_0 = np.random.choice(states, p=[0.55, 0.45])  # Slightly favoring \"High\"\n",
        "    action_1 = np.random.choice(states, p=[0.45, 0.55])  # Slightly favoring \"Low\"\n",
        "    return pd.DataFrame({\"Action(0)\": [action_0], \"Action(1)\": [action_1]})\n",
        "\n",
        "# Function to perform inference in parallel\n",
        "def parallel_inference(process_id):\n",
        "    return generate_categorical_data(seed=process_id)  # Different seed per process\n",
        "\n",
        "# Run parallel inference\n",
        "def run_parallel_inference():\n",
        "    num_processes = 4  # Number of parallel tasks\n",
        "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
        "        results = pool.map(parallel_inference, range(num_processes))  # Pass different IDs as seeds\n",
        "\n",
        "    # Print results in a distinct table format\n",
        "    for idx, res in enumerate(results, 1):\n",
        "        print(f\"=== Inference Result {idx} ===\")\n",
        "        print(\"| Action    | Category  |\")\n",
        "        print(\"|-----------|----------|\")\n",
        "        print(f\"| Action(0) | {res['Action(0)'][0]}      |\")\n",
        "        print(f\"| Action(1) | {res['Action(1)'][0]}      |\")\n",
        "        print(\"========================\\n\")\n",
        "\n",
        "# Ensure it runs properly only in a script (not Jupyter)\n",
        "if __name__ == \"__main__\":\n",
        "    run_parallel_inference()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkiFWCfs4vzu",
        "outputId": "799abd07-e84b-4448-e729-ca9c42fd0f90"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Inference Result 1 ===\n",
            "| Action    | Category  |\n",
            "|-----------|----------|\n",
            "| Action(0) | High      |\n",
            "| Action(1) | Low      |\n",
            "========================\n",
            "\n",
            "=== Inference Result 2 ===\n",
            "| Action    | Category  |\n",
            "|-----------|----------|\n",
            "| Action(0) | High      |\n",
            "| Action(1) | Low      |\n",
            "========================\n",
            "\n",
            "=== Inference Result 3 ===\n",
            "| Action    | Category  |\n",
            "|-----------|----------|\n",
            "| Action(0) | High      |\n",
            "| Action(1) | High      |\n",
            "========================\n",
            "\n",
            "=== Inference Result 4 ===\n",
            "| Action    | Category  |\n",
            "|-----------|----------|\n",
            "| Action(0) | Low      |\n",
            "| Action(1) | Low      |\n",
            "========================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAB 08"
      ],
      "metadata": {
        "id": "lA77EaTu5vmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import multiprocessing\n",
        "from pgmpy.models import DiscreteBayesianNetwork\n",
        "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "# Define a different Bayesian Network structure using DiscreteBayesianNetwork\n",
        "model = DiscreteBayesianNetwork([\n",
        "    ('Shape', 'ROI'), ('Brightness', 'ROI'), ('Edge', 'ROI'), ('Texture', 'ROI')\n",
        "])\n",
        "\n",
        "# Generate synthetic dataset (modified variable names)\n",
        "np.random.seed(99)  # Ensuring different results while keeping reproducibility\n",
        "data = pd.DataFrame(\n",
        "    np.random.randint(0, 4, size=(1000, 5)),  # Changed range to (0,4) for more variability\n",
        "    columns=['Shape', 'Brightness', 'Edge', 'Texture', 'ROI']\n",
        ")\n",
        "\n",
        "# Learn CPDs using Maximum Likelihood Estimation\n",
        "model.fit(data, estimator=MaximumLikelihoodEstimator)\n",
        "\n",
        "# Function to perform inference\n",
        "def perform_inference(evidence):\n",
        "    inference = VariableElimination(model)\n",
        "    result = inference.query(variables=['ROI'], evidence=evidence)\n",
        "    return result\n",
        "\n",
        "# Run inference sequentially\n",
        "def run_inference():\n",
        "    evidences = [\n",
        "        {'Shape': 3},\n",
        "        {'Brightness': 2},\n",
        "        {'Edge': 1},\n",
        "        {'Texture': 0}\n",
        "    ]\n",
        "\n",
        "    results = [perform_inference(evidence) for evidence in evidences]\n",
        "\n",
        "    # Print results in a better format\n",
        "    for idx, res in enumerate(results, 1):\n",
        "        print(f\"===== Inference Result {idx} =====\")\n",
        "        print(res)\n",
        "        print(\"=================================\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_inference()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLgmy0cb5xbl",
        "outputId": "c74c028c-ccf2-4de7-d750-af06f1f298c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Inference Result 1 =====\n",
            "+--------+------------+\n",
            "| ROI    |   phi(ROI) |\n",
            "+========+============+\n",
            "| ROI(0) |     0.2463 |\n",
            "+--------+------------+\n",
            "| ROI(1) |     0.2263 |\n",
            "+--------+------------+\n",
            "| ROI(2) |     0.2755 |\n",
            "+--------+------------+\n",
            "| ROI(3) |     0.2519 |\n",
            "+--------+------------+\n",
            "=================================\n",
            "\n",
            "===== Inference Result 2 =====\n",
            "+--------+------------+\n",
            "| ROI    |   phi(ROI) |\n",
            "+========+============+\n",
            "| ROI(0) |     0.2528 |\n",
            "+--------+------------+\n",
            "| ROI(1) |     0.2541 |\n",
            "+--------+------------+\n",
            "| ROI(2) |     0.2526 |\n",
            "+--------+------------+\n",
            "| ROI(3) |     0.2404 |\n",
            "+--------+------------+\n",
            "=================================\n",
            "\n",
            "===== Inference Result 3 =====\n",
            "+--------+------------+\n",
            "| ROI    |   phi(ROI) |\n",
            "+========+============+\n",
            "| ROI(0) |     0.2556 |\n",
            "+--------+------------+\n",
            "| ROI(1) |     0.2541 |\n",
            "+--------+------------+\n",
            "| ROI(2) |     0.2454 |\n",
            "+--------+------------+\n",
            "| ROI(3) |     0.2448 |\n",
            "+--------+------------+\n",
            "=================================\n",
            "\n",
            "===== Inference Result 4 =====\n",
            "+--------+------------+\n",
            "| ROI    |   phi(ROI) |\n",
            "+========+============+\n",
            "| ROI(0) |     0.2546 |\n",
            "+--------+------------+\n",
            "| ROI(1) |     0.2831 |\n",
            "+--------+------------+\n",
            "| ROI(2) |     0.2391 |\n",
            "+--------+------------+\n",
            "| ROI(3) |     0.2232 |\n",
            "+--------+------------+\n",
            "=================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sklearn-crfsuite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14-ZCMRL6mYi",
        "outputId": "80123df3-20e1-4f04-b6a4-113791e73c7e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn-crfsuite\n",
            "  Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-crfsuite>=0.9.7 (from sklearn-crfsuite)\n",
            "  Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite) (1.6.1)\n",
            "Requirement already satisfied: tabulate>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.11/dist-packages (from sklearn-crfsuite) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (3.6.0)\n",
            "Downloading sklearn_crfsuite-0.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_crfsuite-0.9.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.11 sklearn-crfsuite-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAB 09"
      ],
      "metadata": {
        "id": "lB_sEZjh6p3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn_crfsuite import CRF\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the image and convert it to grayscale\n",
        "image = cv2.imread(\"C:/Users/vsuji/Downloads/animal.jpg\")  # Change to your image file\n",
        "image_path = \"C:/Users/vsuji/Downloads/animal.jpg\"\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\n",
        "h, w = gray.shape\n",
        "\n",
        "# Extract pixel features (intensity and position)\n",
        "def extract_features(img):\n",
        "    features = []\n",
        "    for i in range(h):\n",
        "        for j in range(w):\n",
        "            pixel_intensity = img[i, j]\n",
        "            features.append({\n",
        "                'intensity': pixel_intensity,\n",
        "                'x': i / h,  # Normalize x-coordinate\n",
        "                'y': j / w   # Normalize y-coordinate\n",
        "            })\n",
        "    return features\n",
        "\n",
        "features = extract_features(gray)\n",
        "\n",
        "# Generate synthetic labels (simple thresholding for foreground/background)\n",
        "labels = np.where(gray > 128, 'foreground', 'background').flatten().tolist()\n",
        "\n",
        "# Train the CRF model on the full image\n",
        "crf = CRF(algorithm='lbfgs')\n",
        "crf.fit([features], [labels])  # Train on entire image\n",
        "\n",
        "# Predict labels for the entire image\n",
        "pred_labels = crf.predict([features])[0]\n",
        "\n",
        "# Reshape the predicted labels back to image dimensions\n",
        "output_labels = np.array(pred_labels).reshape(h, w)\n",
        "\n",
        "# Convert labels to binary image format\n",
        "output_img = np.zeros_like(gray)\n",
        "output_img[output_labels == 'foreground'] = 255  # White for foreground\n",
        "\n",
        "# Show the segmented image\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(gray, cmap='gray')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Segmented Image using CRF\")\n",
        "plt.imshow(output_img, cmap='gray')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "b5iaO47j-XQi",
        "outputId": "dff1040e-1cd3-45e3-bf61-0d5daeb34ced"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f0992b2c17b4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:/Users/vsuji/Downloads/animal.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Change to your image file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"C:/Users/vsuji/Downloads/animal.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LAB 10"
      ],
      "metadata": {
        "id": "xYbyNUMZ_-Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate new synthetic data with a different decision boundary\n",
        "np.random.seed(42)  # Different seed for variation\n",
        "X = np.random.uniform(-1, 1, size=(600, 4))  # 600 samples, 4 features, values between -1 and 1\n",
        "y = (X[:, 1] + X[:, 2] > 0.5).astype(int)  # Changed boundary condition\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Train different Logistic Regression models with different regularizations\n",
        "l1_model = LogisticRegression(penalty='l1', solver='liblinear', C=0.6, random_state=42)\n",
        "l2_model = LogisticRegression(penalty='l2', solver='lbfgs', C=1.5, random_state=42)\n",
        "elastic_net_model = LogisticRegression(\n",
        "    penalty='elasticnet', solver='saga', l1_ratio=0.7, C=1.0, max_iter=10000, random_state=42\n",
        ")  # Adjusted l1_ratio and max_iter for better convergence\n",
        "\n",
        "# Train the models\n",
        "l1_model.fit(X_train, y_train)\n",
        "l2_model.fit(X_train, y_train)\n",
        "elastic_net_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_l1 = l1_model.predict(X_test)\n",
        "y_pred_l2 = l2_model.predict(X_test)\n",
        "y_pred_elastic = elastic_net_model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "acc_l1 = accuracy_score(y_test, y_pred_l1)\n",
        "acc_l2 = accuracy_score(y_test, y_pred_l2)\n",
        "acc_elastic = accuracy_score(y_test, y_pred_elastic)\n",
        "\n",
        "# Display results\n",
        "print(\"=\" * 40)\n",
        "print(\"    Model Performance Summary    \")\n",
        "print(\"=\" * 40)\n",
        "print(f\"L1 Regularization Accuracy:    {acc_l1:.3f}\")\n",
        "print(f\"L2 Regularization Accuracy:    {acc_l2:.3f}\")\n",
        "print(f\"Elastic Net Accuracy:          {acc_elastic:.3f}\")\n",
        "print(\"=\" * 40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0jzqO3J_9VL",
        "outputId": "3770fda5-f85c-4a57-908f-b03d09b574e7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "    Model Performance Summary    \n",
            "========================================\n",
            "L1 Regularization Accuracy:    1.000\n",
            "L2 Regularization Accuracy:    1.000\n",
            "Elastic Net Accuracy:          1.000\n",
            "========================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Snippets: Importing libraries",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}